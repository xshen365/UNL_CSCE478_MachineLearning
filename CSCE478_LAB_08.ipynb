{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier - Text Classification - Multinomial & Bernoulli\n",
    "\n",
    "In this notebook you will apply the Naive Bayes algorithms for text classification.\n",
    "\n",
    "Your tasks are marked with task numbers (e.g., Task 1). To get full credit you need to complete **ALL** tasks.\n",
    "\n",
    "\n",
    "\n",
    "### Dataset: The 20 Newsgroups data set\n",
    "\n",
    "\n",
    "The 20 newsgroups dataset comprises around 20,000 newsgroups posts on 20 topics split in two subsets: one for training (or development) and the other one for testing (or for performance evaluation). The 20 newsgroups collection has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering. The split between the train and test set is based upon a messages posted before and after a specific date.\n",
    "\n",
    "Following is a list of the 20 newsgroups, partitioned (more or less) according to subject matter:\n",
    "\n",
    "- alt.atheism\n",
    "- comp.graphics\n",
    "- comp.os.ms-windows.misc\n",
    "- comp.sys.ibm.pc.hardware\n",
    "- comp.sys.mac.hardware\n",
    "- comp.windows.x\n",
    "- misc.forsale\n",
    "- rec.autos\n",
    "- rec.motorcycles\n",
    "- rec.sport.baseball\n",
    "- rec.sport.hockey\n",
    "- sci.crypt\n",
    "- sci.electronics\n",
    "- sci.med\n",
    "- sci.space\n",
    "- soc.religion.christian\n",
    "- talk.politics.guns\n",
    "- talk.politics.mideast\n",
    "- talk.politics.misc\n",
    "- talk.religion.misc\n",
    "\n",
    "\n",
    "You will normalize the documents, perform preprocessing and vectorize the features. Since the features are categorical, you will implement two different naive Bayes classifiers using Scikit-Learn. \n",
    "- Categorical features (binary valued) are modeled using the Multivariate Bernoulli distrubition \n",
    "- Categorical features (multi-valued) are modeled using the Multinomial distrubition \n",
    "\n",
    "\n",
    "## Steps for Classification:\n",
    "\n",
    "1. Exploratory Data Analysis\n",
    "2. Feature Extraction\n",
    "   - a. Text Normalization (Stemming & Lemmatization)\n",
    "   - b. Text Preprocessing (Tokenization, removing stop words, etc.)\n",
    "   - c. Vectorization of the features\n",
    "3. Model Selection by Hyperparameter Tuning\n",
    "4. Train the Optimal Model\n",
    "5. Analyzing Model Performance\n",
    "6. Evaluate the Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/jian/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/jian/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, precision_recall_curve, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "You will work on a partial dataset with only 4 categories out of the 20 available in the dataset:\n",
    "- alt.atheism\n",
    "- soc.religion.christian\n",
    "- comp.graphics\n",
    "- sci.med\n",
    "\n",
    "\n",
    "The samples are shuffled randomly. This is useful if you wish to select only a subset of samples to quickly train a model and get a first idea of the results before re-training on the complete dataset later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and Test Sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']\n",
    "\n",
    "train_data = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "X_train = train_data.data\n",
    "y_train = train_data.target\n",
    "\n",
    "\n",
    "test_data = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
    "X_test = test_data.data\n",
    "y_test = test_data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue> 1. Exploratory Data Analysis</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Check of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Names:  ['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']\n",
      "\n",
      "Number of Training Examples:  2257\n",
      "Number of Training Labels:  2257\n",
      "Number of Test Examples:  1502\n",
      "Number of Test Labels:  1502\n",
      "\n",
      "Print a Random Document:\n",
      "\n",
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "Organization: The City University\n",
      "Lines: 14\n",
      "\n",
      "Does anyone know of a good way (standard PC application/PD utility) to\n",
      "convert tif/img/tga files into LaserJet III format.  We would also like to\n",
      "do the same, converting to HPGL (HP plotter) files.\n",
      "\n",
      "Please email any response.\n",
      "\n",
      "Is this the correct group?\n",
      "\n",
      "Thanks in advance.  Michael.\n",
      "-- \n",
      "Michael Collier (Programmer)                 The Computer Unit,\n",
      "Email: M.P.Collier@uk.ac.city                The City University,\n",
      "Tel: 071 477-8000 x3769                      London,\n",
      "Fax: 071 477-8565                            EC1V 0HB.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Target Names: \", train_data.target_names)\n",
    "\n",
    "print(\"\\nNumber of Training Examples: \", len(X_train))\n",
    "print(\"Number of Training Labels: \", len(y_train))\n",
    "\n",
    "print(\"Number of Test Examples: \",len(X_test))\n",
    "print(\"Number of Test Labels: \", len(y_test))\n",
    "\n",
    "\n",
    "print(\"\\nPrint a Random Document:\\n\")\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Distribution\n",
    "\n",
    "#### Task 1: Compute class distribution in the following block (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data distribution:\n",
      "\n",
      "alt.atheism: 480\n",
      "soc.religion.christian: 584\n",
      "comp.graphics: 594\n",
      "sci.med: 599\n",
      "\n",
      "Test data distribution:\n",
      "\n",
      "alt.atheism: 319\n",
      "soc.religion.christian: 389\n",
      "comp.graphics: 396\n",
      "sci.med: 398\n"
     ]
    }
   ],
   "source": [
    "train_cat_vals = []\n",
    "print(\"Train data distribution:\\n\")\n",
    "for i in range(len(categories)):\n",
    "    print(\"%s: %d\" %(categories[i], sum(y_train==i)))\n",
    "    train_cat_vals.append(sum(y_train==i))\n",
    "print(\"\\nTest data distribution:\\n\")\n",
    "for i in range(len(categories)):\n",
    "    print(\"%s: %d\" %(categories[i], sum(y_test==i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the Class Distribution\n",
    "\n",
    "\n",
    "#### Task 2: Generate visualization of the class distribution in the following block (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.barplot(categories, train_cat_vals, alpha=0.8)\n",
    "plt.xlabel('Categories', fontsize=12)\n",
    "plt.ylabel('Counts', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue> 2. Feature Extraction </font>\n",
    "\n",
    "## a) Text Normalization by Lemmatization\n",
    "\n",
    "Stemming and Lemmatization are Text Normalization (or sometimes called Word Normalization) techniques in the field of Natural Language Processing that are used to prepare text, words, and documents for further processing.\n",
    "\n",
    "\n",
    "#### Task 3: Lemmatize the training data. You may stem it as well, if it improves the classification accuracy. (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', ':', 'dyer', '@', 'spdcc.com', '(', 'steve', 'dyer', ')', 'subject', ':', 're', ':', 'is', 'msg', 'sensitivity', 'superstition', '?', 'organization', ':', 's.p', '.', 'dyer', 'computer', 'consulting', ',', 'cambridge', 'ma', 'lines', ':', '14', 'in', 'article', '<', '1qnns0', '$', '4l3', '@', 'agate.berkeley.edu', '>', 'spp', '@', 'zabriskie.berkeley.edu', '(', 'steve', 'pope', ')', 'writes', ':', '>', 'the', 'mass', 'of', 'anectdotal', 'evidence', ',', 'combined', 'with', 'the', 'lack', 'of', '>', 'a', 'properly', 'constructed', 'scientific', 'experiment', 'disproving', '>', 'the', 'hypothesis', ',', 'makes', 'the', 'msg', 'reaction', 'hypothesis', 'the', '>', 'most', 'likely', 'explanation', 'for', 'events', '.', 'you', 'forgot', 'the', 'smiley-face', '.', 'i', 'ca', \"n't\", 'believe', 'this', 'is', 'what', 'they', 'turn', 'out', 'at', 'berkeley', '.', 'tell', 'me', 'you', \"'re\", 'an', 'aberration', '.', '--', 'steve', 'dyer', 'dyer', '@', 'ursa-major.spdcc.com', 'aka', '{', 'ima', ',', 'harvard', ',', 'rayssd', ',', 'linus', ',', 'm2c', '}', '!', 'spdcc', '!', 'dyer']\n",
      "CPU times: user 16.7 s, sys: 140 ms, total: 16.8 s\n",
      "Wall time: 16.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "X_train_lemmatized = []\n",
    "X_test_lemmatized = []\n",
    "for i in range(len(X_train)):\n",
    "    train_lower = nltk.word_tokenize(X_train[i].lower())\n",
    "    X_train_lemmatized.append(' '.join(lemmatizer.lemmatize(w) for w in train_lower))\n",
    "for i in range(len(X_test)):\n",
    "    test_lower = nltk.word_tokenize(X_test[i].lower())\n",
    "    X_test_lemmatized.append(' '.join(lemmatizer.lemmatize(q) for q in test_lower))\n",
    "print(train_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "Organization: The City University\n",
      "Lines: 14\n",
      "\n",
      "Does anyone know of a good way (standard PC application/PD utility) to\n",
      "convert tif/img/tga files into LaserJet III format.  We would also like to\n",
      "do the same, converting to HPGL (HP plotter) files.\n",
      "\n",
      "Please email any response.\n",
      "\n",
      "Is this the correct group?\n",
      "\n",
      "Thanks in advance.  Michael.\n",
      "-- \n",
      "Michael Collier (Programmer)                 The Computer Unit,\n",
      "Email: M.P.Collier@uk.ac.city                The City University,\n",
      "Tel: 071 477-8000 x3769                      London,\n",
      "Fax: 071 477-8565                            EC1V 0HB.\n",
      "\n",
      "\n",
      "Lemmatized Sample:\n",
      "\n",
      "from : sd345 @ city.ac.uk ( michael collier ) subject : converting image to hp laserjet iii ? nntp-posting-host : hampton organization : the city university line : 14 doe anyone know of a good way ( standard pc application/pd utility ) to convert tif/img/tga file into laserjet iii format . we would also like to do the same , converting to hpgl ( hp plotter ) file . please email any response . is this the correct group ? thanks in advance . michael . -- michael collier ( programmer ) the computer unit , email : m.p.collier @ uk.ac.city the city university , tel : 071 477-8000 x3769 london , fax : 071 477-8565 ec1v 0hb .\n"
     ]
    }
   ],
   "source": [
    "#X_train_lemmatized_df = pd.DataFrame(X_train_lemmatized)\n",
    "#y_train_df = pd.DataFrame(y_train)\n",
    "print(X_train[0])\n",
    "print('\\nLemmatized Sample:\\n')\n",
    "print(X_train_lemmatized[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue> 2. Feature Extraction </font>\n",
    "\n",
    "## b) Text Preprocessing & c) Feature Vectorization\n",
    "\n",
    "We can combine text preprocessing, feature vectorization and model training using the sklearn Pipeline object. This Pipeline object can be used for model selection and for training the optimal model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=blue> 3. Model Selection </font>\n",
    "\n",
    "\n",
    "There are no hyperparameters in a NB model except the Laplace smoothing parameter alpha.\n",
    "\n",
    "However, there are multiple hyperparameters for the CountVectorizer() and TfidfTransformer(). We need to select the best model based on the optimal values of these hyperparameters. This process is called hyper-parameter tuning.\n",
    "\n",
    "For hyperparameter tuning, we will build a compund classifier using the sklearn Pipeline class. It will combine the CountVectorizer(), TfidfTransformer() and MultinomialNB() objects and will create a single object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Pipeline for Hyperparameter Tuning\n",
    "\n",
    "\n",
    "#### Task 4: Build a Pipeline object by combining CountVectorizer() and MultinomialNB() (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_multinomial = Pipeline([('vect', CountVectorizer()), \n",
    "                                 ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "#### Task 5: Perform hyperparamer tuning for the following hyperparameters: (5 pts)\n",
    "- CountVectorizer()\n",
    "         -- ngram_range\n",
    "         -- stop_words\n",
    "- MultinomialNB()\n",
    "        -- alpha\n",
    "        \n",
    "## **<font color=red size=5>Important:</font>**\n",
    "\n",
    "The GridSearchCV takes an argument to define the scoring metric (performance measure). \n",
    "\n",
    "See the list of possible scoring functions:\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "\n",
    "For multiclass classification, we may use \"f1_micro\" scoring function. The f1_micro function is the average of the F1 score of each class with weighting depending on the average parameter.\n",
    "\n",
    "The macro-average (\"f1_macro\") will compute the metric independently for each class and then take the average (hence treating all classes equally), whereas a micro-average (\"f1_micro\") will aggregate the contributions of all classes to compute the average metric. In a multi-class classification setup, micro-average is preferable if you suspect there might be class imbalance (i.e you may have many more examples of one class than of other classes).\n",
    "\n",
    "In the binary classification, \"f1\" score function can be used. We may also use the precision_score, recall_score, roc_auc_score functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done 140 out of 140 | elapsed:   36.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Score: 0.981470\n",
      "\n",
      "Optimal Hyperparameter Values: \n",
      "clf__alpha: 0.001\n",
      "vect__ngram_range: (1, 2)\n",
      "vect__stop_words: 'english'\n",
      "CPU times: user 4.48 s, sys: 687 ms, total: 5.17 s\n",
      "Wall time: 38.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'vect__ngram_range': [(1,1), (1,2)],\n",
    "             'vect__stop_words': ['english', None],\n",
    "             'clf__alpha': [0.0001, 0.001, 0.01, 0.1, 1.0, 1.5, 2.0]}\n",
    "\n",
    "clf_multinomial_cv = GridSearchCV(text_clf_multinomial, param_grid,\n",
    "                                 scoring='f1_macro', cv=5, verbose=1,\n",
    "                                 n_jobs=-1)\n",
    "\n",
    "clf_multinomial_cv = clf_multinomial_cv.fit(X_train_lemmatized, y_train)\n",
    "\n",
    "params_optimal_clf_multinomial = clf_multinomial_cv.best_params_\n",
    "\n",
    "\n",
    "print(\"\\nBest Score: %f\" %clf_multinomial_cv.best_score_)\n",
    "\n",
    "print(\"\\nOptimal Hyperparameter Values: \")\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print('%s: %r' %(param_name, params_optimal_clf_multinomial[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue> 4. Train the Optimal Multinomial Model </font>\n",
    "\n",
    "#### Task 6: Using the optimal hyperparameter values, create the optimal model. Then, fit the model. (10 pts)\n",
    "- Build a Pipeline object by combining CountVectorizer() and MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 2), preprocessor=None,\n",
       "                                 stop_words='english', strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomial_clf = Pipeline([('vect', CountVectorizer(stop_words='english',\n",
    "                                                    ngram_range=(1,2),\n",
    "                                                    binary=False)), \n",
    "                            ('clf', MultinomialNB(alpha=0.001))\n",
    "                           ])\n",
    "\n",
    "multinomial_clf.fit(X_train_lemmatized, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue> 6. Evaluate the Model on Test Data </font>\n",
    "\n",
    "#### Task 7:  Evaluate the model on test data and generate (10 pts)\n",
    "- Confusion Matrix\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 score\n",
    "- Classification Report\n",
    "\n",
    "\n",
    "### Note: For multi-class classification, set the \"average\" attribute to \"micro\" for the following functions:\n",
    "- precision_score\n",
    "- recall_score\n",
    "- f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Confusion Matrix:\n",
      "[[299   4   4  12]\n",
      " [  6 371  10   2]\n",
      " [  3  24 356  13]\n",
      " [  5   5   4 384]]\n",
      "\n",
      "Test Precision: 0.939942\n",
      "\n",
      "Test Recall: 0.938711\n",
      "\n",
      "Test F1 Score: 0.938971\n",
      "\n",
      "Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.96      0.94      0.95       319\n",
      "soc.religion.christian       0.92      0.95      0.94       389\n",
      "         comp.graphics       0.95      0.90      0.92       396\n",
      "               sci.med       0.93      0.96      0.95       398\n",
      "\n",
      "              accuracy                           0.94      1502\n",
      "             macro avg       0.94      0.94      0.94      1502\n",
      "          weighted avg       0.94      0.94      0.94      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = multinomial_clf.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_pred, average='macro')\n",
    "print(\"\\nTest Precision: %f\" %precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, y_test_pred, average='macro')\n",
    "print(\"\\nTest Recall: %f\" %recall_test)\n",
    "\n",
    "f1_test = f1_score(y_test, y_test_pred, average='macro')\n",
    "print(\"\\nTest F1 Score: %f\" %f1_test)\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Multinomial NB: TF-IDF Model\n",
    "\n",
    "#### Task 8: Implement the Multinomial model using the TF-IDF feature vectors (10 pts)\n",
    "- Build a Pipeline object by combining CountVectorizer(), TfidfTransformer() and MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 2), preprocessor=None,\n",
       "                                 stop_words='english', strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomial_clf_tfidf = Pipeline([('vect', \n",
    "                                   CountVectorizer(stop_words='english',\n",
    "                                  ngram_range=(1,2), binary=False)), \n",
    "                                  ('tfidf', TfidfTransformer()),\n",
    "                                  ('clf', MultinomialNB(alpha=0.001))\n",
    "                                 ])\n",
    "\n",
    "multinomial_clf_tfidf.fit(X_train_lemmatized, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model on Test Data \n",
    "\n",
    "#### Task 9: Evaluate the model on test data and generate (10 pts)\n",
    "- Confusion Matrix\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 score\n",
    "- Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Confusion Matrix:\n",
      "[[290   4   7  18]\n",
      " [  6 368  11   4]\n",
      " [  3  22 356  15]\n",
      " [  5   2   6 385]]\n",
      "\n",
      "Test Precision: 0.933101\n",
      "\n",
      "Test Recall: 0.930358\n",
      "\n",
      "Test F1 Score: 0.931277\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93       319\n",
      "           1       0.93      0.95      0.94       389\n",
      "           2       0.94      0.90      0.92       396\n",
      "           3       0.91      0.97      0.94       398\n",
      "\n",
      "    accuracy                           0.93      1502\n",
      "   macro avg       0.93      0.93      0.93      1502\n",
      "weighted avg       0.93      0.93      0.93      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred_tfidf = multinomial_clf_tfidf.predict(X_test_lemmatized)\n",
    "\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_tfidf))\n",
    "\n",
    "precision_test_tfidf = precision_score(y_test, y_test_pred_tfidf, average='macro')\n",
    "print(\"\\nTest Precision: %f\" %precision_test_tfidf)\n",
    "\n",
    "recall_test_tfidf = recall_score(y_test, y_test_pred_tfidf, average='macro')\n",
    "print(\"\\nTest Recall: %f\" %recall_test_tfidf)\n",
    "\n",
    "f1_test_tfidf = f1_score(y_test, y_test_pred_tfidf, average='macro')\n",
    "print(\"\\nTest F1 Score: %f\" %f1_test_tfidf)\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=maroon> Observation on Multinomial Model With TF-IDF Feature Vectors </font>\n",
    "\n",
    "We observe that both precision and recall decrease with TF-IDF feature vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Multivariate Bernoulli NB\n",
    "\n",
    "#### Task 10: Implement the Multivariate Bernoulli Model (10 pts)\n",
    "- Build a Pipeline object by combining CountVectorizer() and BernoulliNB()\n",
    "\n",
    "### <font color=red> Note: </font>\n",
    "The \"binary\" attribute of the CountVectorizer() object should be set to \"True\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 140 out of 140 | elapsed:   37.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Score: 0.973774\n",
      "\n",
      "Optimal Parameters:\n",
      "\n",
      "clf__alpha: 0.0001\n",
      "vect__ngram_range: (1, 1)\n",
      "vect__stop_words: 'english'\n",
      "CPU times: user 3.7 s, sys: 559 ms, total: 4.26 s\n",
      "Wall time: 38.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf_bernoulli = Pipeline([('vect', CountVectorizer(binary=True)), \n",
    "                            ('clf', BernoulliNB())\n",
    "                           ])\n",
    "\n",
    "\n",
    "param_grid = {'vect__ngram_range': [(1,1), (1,2)],\n",
    "             'vect__stop_words': ['english', None],\n",
    "             'clf__alpha': [0.0001, 0.001, 0.01, 0.1, 1.0, 1.5, 2.0]\n",
    "             }\n",
    "\n",
    "clf_bernoulli_cv = GridSearchCV(clf_bernoulli, param_grid, scoring='f1_macro',\n",
    "                               cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "clf_bernoulli_cv = clf_bernoulli_cv.fit(X_train_lemmatized, y_train)\n",
    "\n",
    "params_optimal_clf_bernoulli = clf_bernoulli_cv.best_params_\n",
    "\n",
    "print('\\nBest Score: %f' %clf_bernoulli_cv.best_score_)\n",
    "print('\\nOptimal Parameters:\\n')\n",
    "\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print('%s: %r' %(param_name, params_optimal_clf_bernoulli[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=True,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words='english', strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('clf',\n",
       "                 BernoulliNB(alpha=0.0001, binarize=0.0, class_prior=None,\n",
       "                             fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model best parameters\n",
    "bernoulli_clf = Pipeline([('vect', CountVectorizer(stop_words='english', \n",
    "                          ngram_range=(1,1),\n",
    "                          binary=True)), \n",
    "                          ('clf', BernoulliNB(alpha=0.0001))]\n",
    "                        )\n",
    "bernoulli_clf.fit(X_train_lemmatized, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model on Test Data \n",
    "\n",
    "\n",
    "#### Task 11: Evaluate the model on test data and generate (10 pts)\n",
    "- Confusion Matrix\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 score\n",
    "- Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Confusion Matrix:\n",
      "[[286   7   8  18]\n",
      " [  3 373  11   2]\n",
      " [  2  33 357   4]\n",
      " [  5  11   7 375]]\n",
      "\n",
      "Test Precision: 0.929474\n",
      "\n",
      "Test Recall: 0.924787\n",
      "\n",
      "Test F1 Score: 0.926315\n",
      "\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93       319\n",
      "           1       0.88      0.96      0.92       389\n",
      "           2       0.93      0.90      0.92       396\n",
      "           3       0.94      0.94      0.94       398\n",
      "\n",
      "    accuracy                           0.93      1502\n",
      "   macro avg       0.93      0.92      0.93      1502\n",
      "weighted avg       0.93      0.93      0.93      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred_bernoulli = bernoulli_clf.predict(X_test_lemmatized)\n",
    "\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_bernoulli))\n",
    "\n",
    "precision_test_bernoulli = precision_score(y_test, y_test_pred_bernoulli, average='macro')\n",
    "print(\"\\nTest Precision: %f\" %precision_test_bernoulli)\n",
    "\n",
    "recall_test_bernoulli = recall_score(y_test, y_test_pred_bernoulli, average='macro')\n",
    "print(\"\\nTest Recall: %f\" %recall_test_bernoulli)\n",
    "\n",
    "f1_test_bernoulli = f1_score(y_test, y_test_pred_bernoulli, average='macro')\n",
    "print(\"\\nTest F1 Score: %f\" %f1_test_bernoulli)\n",
    "\n",
    "classification_report_test_bernoulli = classification_report(y_test, y_test_pred_bernoulli)\n",
    "print(\"\\nClassification Report:\", classification_report_test_bernoulli)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=maroon> Observation on Multivariate Bernoulli Model </font>\n",
    "\n",
    "#### Task 12: Write a short account of your observation on the following aspects of your experimentation with 3 NB classifiers (10 pts):\n",
    "- Impact of data normalization technique (did you observe performance improvement with lemmatization and/or stemming)\n",
    "- Which classifier gave the best precision? Best recall? Best F1 Score? Explain their performance variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4, color=navy> - Yes, there is a improvement with lemmatization. Lemmatization saves a lof of space and ignores many unnecessary tabs and thus improves correctness of classification.</font>\n",
    "<pre></pre>\n",
    "<font size=4, color=navy> - The multinomial Naive Bayes classifier gave the best precision, recall and f1 score. multinomial gave all the best scores, and multinomial with TF-IDF ranks second, the bernoulli NB classifier gave the lowest score. Since the text occurrance matters so multinomial performs better on classification than bernoulli classifier.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
